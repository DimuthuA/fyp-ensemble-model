{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d1e774-ef84-4e7a-b2c8-d0dac521f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82cd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Helper Functions --------------------\n",
    "\n",
    "# def add_prediction_column(base_df, new_df, new_col_name):\n",
    "#     # Ensure 'actual' in new_df is rounded and converted to int\n",
    "#     new_df = new_df.copy()\n",
    "#     new_df['actual'] = new_df['actual'].round().astype(int)\n",
    "\n",
    "#     grouped_base = base_df.groupby('geocode')\n",
    "#     grouped_new = new_df.groupby('geocode')\n",
    "#     aligned_preds = []\n",
    "\n",
    "#     for geocode, base_group in grouped_base:\n",
    "#         new_group = grouped_new.get_group(geocode)\n",
    "#         assert len(base_group) == len(new_group), f\"Row count mismatch for geocode {geocode}\"\n",
    "\n",
    "#         base_actuals = base_group['actual'].values\n",
    "#         new_actuals = new_group['actual'].values\n",
    "#         if not np.array_equal(base_actuals, new_actuals):\n",
    "#             mismatches = np.where(base_actuals != new_actuals)[0]\n",
    "#             for idx in mismatches:\n",
    "#                 week = base_group.iloc[idx]['week']\n",
    "#                 base_val = base_actuals[idx]\n",
    "#                 new_val = new_actuals[idx]\n",
    "#                 print(f\"Geocode {geocode}, row {idx}, week {week}: base actual = {base_val}, new actual = {new_val}\")\n",
    "#             raise AssertionError(f\"Actual mismatch for geocode {geocode}\")\n",
    "\n",
    "#         aligned_preds.extend(new_group[new_col_name].values)\n",
    "\n",
    "#     base_df[new_col_name] = aligned_preds\n",
    "#     return base_df\n",
    "\n",
    "def add_prediction_column(base_df, new_df, new_col_name):\n",
    "    new_df = new_df.copy()\n",
    "    new_df['actual'] = new_df['actual'].round().astype(int)\n",
    "\n",
    "    # Merge on geocode and week\n",
    "    merged = base_df[['geocode', 'week', 'actual']].merge(\n",
    "        new_df[['geocode', 'week', 'actual', new_col_name]],\n",
    "        on=['geocode', 'week'],\n",
    "        how='left',\n",
    "        suffixes=('_base', '_new')\n",
    "    )\n",
    "\n",
    "    # Validate actual values (with tolerance)\n",
    "    actual_base = merged['actual_base'].values\n",
    "    actual_new = merged['actual_new'].values\n",
    "    diffs = np.abs(actual_base - actual_new)\n",
    "    mismatches = np.where(diffs > 1)[0]\n",
    "\n",
    "    if len(mismatches) > 0:\n",
    "        for idx in mismatches:\n",
    "            row = merged.iloc[idx]\n",
    "            print(f\"Geocode {row['geocode']}, week {row['week']}: base actual = {row['actual_base']}, new actual = {row['actual_new']}\")\n",
    "        raise AssertionError(\"Actual mismatch (tolerance exceeded)\")\n",
    "\n",
    "    # Merge prediction column to base_df\n",
    "    base_df = base_df.merge(\n",
    "        new_df[['geocode', 'week', new_col_name]],\n",
    "        on=['geocode', 'week'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return base_df\n",
    "\n",
    "\n",
    "def drop_first_n_rows_per_geocode(df, n=8):\n",
    "    return df.groupby('geocode', group_keys=False).apply(lambda group: group.iloc[n:]).reset_index(drop=True)\n",
    "\n",
    "def load_and_prepare_model_preds(years, model_name, file_pattern, column_name):\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        path = file_pattern.format(year)\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.rename(columns={column_name: model_name})\n",
    "        df['actual'] = df['actual'].round().astype(int)\n",
    "        df['year'] = year\n",
    "        \n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def load_and_prepare_model_preds_handle_missing(years, model_name, file_pattern, column_name):\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        path = file_pattern.format(year)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Convert the prediction column to numeric, coercing errors (empty to NaN)\n",
    "        df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
    "\n",
    "        # Rename the prediction column to model_name\n",
    "        df = df.rename(columns={column_name: model_name})\n",
    "\n",
    "        # Round 'actual' to int only if no missing values, otherwise keep as float (or drop rows with missing actual later)\n",
    "        df['actual'] = pd.to_numeric(df['actual'], errors='coerce').round()\n",
    "\n",
    "        df['year'] = year\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae188db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['geocode', 'week', 'XGBoost', 'actual', 'year'], dtype='object')\n",
      "Index(['geocode', 'week', 'SVR', 'actual', 'year'], dtype='object')\n",
      "Index(['geocode', 'week', 'RF', 'actual', 'year'], dtype='object')\n",
      "Index(['geocode', 'week', 'CatBoost', 'actual', 'year'], dtype='object')\n",
      "Index(['geocode', 'week', 'LightGBM', 'actual', 'year'], dtype='object')\n",
      "Index(['geocode', 'LSTM', 'actual', 'year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load and Combine Base Model Predictions (2019â€“2021) --------------------\n",
    "\n",
    "years = [2019, 2020, 2021]\n",
    "xgboost_df = load_and_prepare_model_preds(years, 'XGBoost', \"../base_predictions/xgboost_preds_{}.csv\", 'xgboost_pred')\n",
    "svr_df = load_and_prepare_model_preds(years, 'SVR', \"../base_predictions/svr_preds_{}.csv\", 'svr_pred')\n",
    "rf_df = load_and_prepare_model_preds(years, 'RF', \"../base_predictions/rf_preds_{}.csv\", 'rf_pred')\n",
    "catboost_df = load_and_prepare_model_preds(years, 'CatBoost', \"../base_predictions/catboost_preds_{}.csv\", 'catboost_pred')\n",
    "lightgbm_df = load_and_prepare_model_preds(years, 'LightGBM', \"../base_predictions/lightgbm_preds_{}.csv\", 'lightgbm_predict')\n",
    "lstm_df = load_and_prepare_model_preds_handle_missing(years, 'LSTM', \"../base_predictions/lstm_preds_{}.csv\", 'lstm_pred')\n",
    "\n",
    "\n",
    "for df in [xgboost_df, svr_df, rf_df, catboost_df, lightgbm_df, lstm_df]:\n",
    "  print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a6c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per feature:\n",
      "XGBoost       0\n",
      "SVR           0\n",
      "RF            0\n",
      "CatBoost      0\n",
      "LightGBM      0\n",
      "LSTM        364\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Assemble Training Set --------------------\n",
    "\n",
    "ensemble_df = xgboost_df[['geocode', 'week', 'actual', 'year', 'XGBoost']].copy()\n",
    "ensemble_df['actual'] = ensemble_df['actual'].round().astype(int)\n",
    "\n",
    "ensemble_df = add_prediction_column(ensemble_df, svr_df, 'SVR')\n",
    "ensemble_df = add_prediction_column(ensemble_df, rf_df, 'RF')\n",
    "ensemble_df = add_prediction_column(ensemble_df, catboost_df, 'CatBoost')\n",
    "\n",
    "# Sort lightgbm_df and lstm_df by geocode and year\n",
    "lightgbm_df = lightgbm_df.sort_values(by=['geocode', 'year', 'week']).reset_index(drop=True)\n",
    "lstm_df = lstm_df.sort_values(by=['geocode', 'year']).reset_index(drop=True)\n",
    "\n",
    "# We'll add 'LSTM' column to lightgbm_df matching rows group-wise\n",
    "lstm_col = 'LSTM'\n",
    "\n",
    "result_groups = []\n",
    "for (geocode, year), lb_group in lightgbm_df.groupby(['geocode', 'year']):\n",
    "    lstm_group = lstm_df[(lstm_df['geocode'] == geocode) & (lstm_df['year'] == year)]\n",
    "    if len(lb_group) != len(lstm_group):\n",
    "        raise ValueError(f\"Row count mismatch for geocode {geocode}, year {year}\")\n",
    "    lb_group = lb_group.copy()\n",
    "    lb_group[lstm_col] = lstm_group[lstm_col].values\n",
    "    result_groups.append(lb_group)\n",
    "\n",
    "lightgbm_df = pd.concat(result_groups, ignore_index=True)\n",
    "\n",
    "ensemble_df = add_prediction_column(ensemble_df, lightgbm_df, 'LightGBM')\n",
    "ensemble_df = ensemble_df.merge(\n",
    "    lightgbm_df[['geocode', 'week', 'LSTM']], \n",
    "    on=['geocode', 'week'], \n",
    "    how='left'\n",
    ") \n",
    "\n",
    "# Sort to get desired order: geocode-wise, then week-wise\n",
    "ensemble_df = ensemble_df.sort_values(by=['geocode', 'week']).reset_index(drop=True)\n",
    "\n",
    "features = ['XGBoost', 'SVR', 'RF', 'CatBoost', 'LightGBM', 'LSTM']\n",
    "\n",
    "# Check and remove rows with NaNs in prediction columns\n",
    "print(\"\\nMissing values per feature:\")\n",
    "print(ensemble_df[features].isnull().sum())\n",
    "\n",
    "# Drop rows with any missing predictions\n",
    "ensemble_df = ensemble_df.dropna(subset=features)\n",
    "\n",
    "X = ensemble_df[features].values\n",
    "y = ensemble_df['actual'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4503ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'learning_rate': [0.05, 0.1, 0.2],\n",
    "#     'max_depth': [2, 3, 4]\n",
    "# }\n",
    "\n",
    "# gbr = GradientBoostingRegressor(random_state=42)\n",
    "# grid_search = GridSearchCV(gbr, param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best model\n",
    "# meta_model = grid_search.best_estimator_\n",
    "# print(f\"\\nBest Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# y_pred = meta_model.predict(X_val)\n",
    "\n",
    "# mae = mean_absolute_error(y_val, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "# print(f\"\\nEvaluation on Test Data:\")\n",
    "# print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd189bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------- Train and Evaluate Meta-Models --------------------\n",
    "\n",
    "# meta_models = {\n",
    "#     'Ridge': Ridge(),\n",
    "#     'Lasso': Lasso(),\n",
    "#     'LinearRegression': LinearRegression()\n",
    "# }\n",
    "\n",
    "# param_grids = {\n",
    "#     'Ridge': {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "#     'Lasso': {'alpha': [0.001, 0.01, 0.1, 1.0]},\n",
    "#     'LinearRegression': {}  # No params\n",
    "# }\n",
    "\n",
    "# meta_model = None\n",
    "# lowest_rmse = float('inf')\n",
    "\n",
    "# for name, model in meta_models.items():\n",
    "#     print(f\"\\n--- Training {name} ---\")\n",
    "#     grid_search = GridSearchCV(model, param_grids[name], scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     y_pred = best_model.predict(X_val)\n",
    "#     mae = mean_absolute_error(y_val, y_pred)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "#     print(f\"{name} â€” MAE: {mae:.4f}, RMSE: {rmse:.4f}, Best Params: {grid_search.best_params_}\")\n",
    "\n",
    "#     if rmse < lowest_rmse:\n",
    "#         lowest_rmse = rmse\n",
    "#         meta_model = best_model\n",
    "\n",
    "# print(f\"\\nBest Meta-Model: {meta_model.__class__.__name__} with RMSE: {lowest_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475eeb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training SVR ---\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "SVR â€” MAE: 2.3619, RMSE: 15.0964, Best Params: {'svr__C': 1, 'svr__degree': 2, 'svr__epsilon': 1.0, 'svr__gamma': 'scale', 'svr__kernel': 'linear'}\n",
      "\n",
      "Best Meta-Model: Pipeline with RMSE: 15.0964\n"
     ]
    }
   ],
   "source": [
    "meta_models = {\n",
    "    # 'Ridge': Ridge(),\n",
    "    # 'Lasso': Lasso(),\n",
    "    # 'LinearRegression': LinearRegression(),\n",
    "    \n",
    "    # SVR with StandardScaler inside a pipeline\n",
    "    'SVR': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', SVR())\n",
    "    ])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "    'Lasso': {'alpha': [0.001, 0.01, 0.1, 1.0]},\n",
    "    'LinearRegression': {},  # No hyperparameters\n",
    "\n",
    "    # Use prefix 'svr__' because SVR is inside the pipeline under name 'svr'\n",
    "    # 'SVR': {\n",
    "    #     'svr__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    #     'svr__C': [0.1, 1, 10, 100],\n",
    "    #     'svr__gamma': ['scale', 'auto'],\n",
    "    #     'svr__degree': [2, 3],  # Only used by 'poly' kernel\n",
    "    #     'svr__epsilon': [0.1, 0.2]\n",
    "    # }\n",
    "\n",
    "        'SVR': {\n",
    "        'svr__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'svr__C': [0.1, 1],\n",
    "        'svr__gamma': ['scale', 'auto'],\n",
    "        'svr__degree': [2, 3],  # Only used by 'poly' kernel\n",
    "        'svr__epsilon': [0.001, 0.01, 0.1, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "meta_model = None\n",
    "lowest_rmse = float('inf')\n",
    "\n",
    "for name, model in meta_models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    print(f\"{name} â€” MAE: {mae:.4f}, RMSE: {rmse:.4f}, Best Params: {grid_search.best_params_}\")\n",
    "\n",
    "    if rmse < lowest_rmse:\n",
    "        lowest_rmse = rmse\n",
    "        meta_model = best_model\n",
    "\n",
    "print(f\"\\nBest Meta-Model: {meta_model.__class__.__name__} with RMSE: {lowest_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad125a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Load 2022 Predictions for Testing --------------------\n",
    "def load_test_df(file_path, model_name, pred_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.rename(columns={pred_col: model_name})\n",
    "    if 'actual' in df.columns:\n",
    "        df['actual'] = pd.to_numeric(df['actual'], errors='coerce').round()\n",
    "    return df\n",
    "\n",
    "def load_lstm_test_df(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.rename(columns={'lstm_pred': 'LSTM'})\n",
    "    df['actual'] = pd.to_numeric(df['actual'], errors='coerce').round().astype('Int64')\n",
    "    return df\n",
    "\n",
    "\n",
    "xgboost_test_df = load_test_df(\"../base_predictions/xgboost_preds_2022.csv\", 'XGBoost', 'xgboost_pred')\n",
    "svr_test_df = load_test_df(\"../base_predictions/svr_preds_2022.csv\", 'SVR', 'svr_pred')\n",
    "rf_test_df = load_test_df(\"../base_predictions/rf_preds_2022.csv\", 'RF', 'rf_pred')\n",
    "catboost_test_df = load_test_df(\"../base_predictions/catboost_preds_2022.csv\", 'CatBoost', 'catboost_pred')\n",
    "lightgbm_test_df = load_test_df(\"../base_predictions/lightgbm_preds_2022.csv\", 'LightGBM', 'lightgbm_predict')\n",
    "lstm_test_df = load_lstm_test_df(\"../base_predictions/lstm_preds_2022.csv\")\n",
    "\n",
    "# Reset index to ensure identical row ordering\n",
    "lightgbm_test_df = lightgbm_test_df.sort_values(by=['geocode', 'week']).reset_index(drop=True)\n",
    "lstm_test_df = lstm_test_df.reset_index(drop=True)\n",
    "\n",
    "# Check alignment\n",
    "if len(lightgbm_test_df) != len(lstm_test_df):\n",
    "    raise ValueError(\"Row count mismatch between LightGBM and LSTM test sets\")\n",
    "\n",
    "# Add LSTM column\n",
    "lightgbm_test_df['LSTM'] = lstm_test_df['LSTM'].values\n",
    "\n",
    "\n",
    "# Start with XGBoost + ground truth\n",
    "ensemble_eval_df = xgboost_test_df[['geocode', 'week', 'actual', 'XGBoost']].copy()\n",
    "\n",
    "# Add other predictions\n",
    "ensemble_eval_df = add_prediction_column(ensemble_eval_df, svr_test_df, 'SVR')\n",
    "ensemble_eval_df = add_prediction_column(ensemble_eval_df, rf_test_df, 'RF')\n",
    "ensemble_eval_df = add_prediction_column(ensemble_eval_df, catboost_test_df, 'CatBoost')\n",
    "ensemble_eval_df = add_prediction_column(ensemble_eval_df, lightgbm_test_df, 'LightGBM')\n",
    "\n",
    "# Finally add LSTM predictions from LightGBM df\n",
    "ensemble_eval_df['LSTM'] = lightgbm_test_df['LSTM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41664282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Hold-out Set (2022):\n",
      "MAE  = 2.3411\n",
      "RMSE = 8.6770\n",
      "RÂ²   = 0.8391\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Generate and Save Ensemble Predictions --------------------\n",
    "\n",
    "X_2022 = ensemble_eval_df[features].values\n",
    "ensemble_eval_df['ensemble_pred'] = meta_model.predict(X_2022)\n",
    "\n",
    "# Set negative predictions to 0 (dengue cases can't be negative)\n",
    "ensemble_eval_df['ensemble_pred'] = ensemble_eval_df['ensemble_pred'].clip(lower=0)\n",
    "\n",
    "ensemble_eval_df.to_csv(\"../ensemble_predictions/final_ensemble_predictions_2022.csv\", index=False)\n",
    "\n",
    "# Evaluation\n",
    "if 'actual' in ensemble_eval_df.columns:\n",
    "    y_true = ensemble_eval_df['actual']\n",
    "    y_pred = ensemble_eval_df['ensemble_pred']\n",
    "\n",
    "    mae_2022 = mean_absolute_error(y_true, y_pred)\n",
    "    rmse_2022 = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2_2022 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nEvaluation on Hold-out Set (2022):\")\n",
    "    print(f\"MAE  = {mae_2022:.4f}\")\n",
    "    print(f\"RMSE = {rmse_2022:.4f}\")\n",
    "    print(f\"RÂ²   = {r2_2022:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1657a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Plotting Results per Geocode --------------------\n",
    "\n",
    "output_dir = \"../ensemble_predictions/plots_2022\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_cols = ['XGBoost', 'SVR', 'RF', 'CatBoost', 'LightGBM', 'LSTM']\n",
    "\n",
    "for geocode in ensemble_eval_df['geocode'].unique():\n",
    "    df_geo = ensemble_eval_df[ensemble_eval_df['geocode'] == geocode].sort_values(by='week')\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.plot(df_geo['week'], df_geo['actual'], label='Actual', color='black', linewidth=2.5, linestyle='--')\n",
    "    for model in model_cols:\n",
    "        plt.plot(df_geo['week'], df_geo[model], label=model, linewidth=1.2)\n",
    "    plt.plot(df_geo['week'], df_geo['ensemble_pred'], label='Ensemble', color='blue', linewidth=2.5)\n",
    "\n",
    "    plt.title(f\"Geocode {geocode} â€” 2022 Predictions vs Actual\")\n",
    "    plt.xlabel(\"Week\")\n",
    "    plt.ylabel(\"Dengue Cases\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"geocode_{geocode}.png\"))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
