{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906251f-3c2f-44f2-8e63-7cade6010e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5dfb2-eb95-4ecd-a85d-c1b9995bbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Predictions from Base Models\n",
    "lstm_preds = pd.read_csv(\"lstm_preds.csv\", header=None, names=[\"LSTM\"])\n",
    "xgboost_preds = pd.read_csv(\"xgboost_preds.csv\", header=None, names=[\"XGBoost\"])\n",
    "lightgbm_preds = pd.read_csv(\"lightgbm_preds.csv\", header=None, names=[\"LightGBM\"])\n",
    "svr_preds = pd.read_csv(\"svr_preds.csv\", header=None, names=[\"SVR\"])\n",
    "rf_preds = pd.read_csv(\"random_forest_preds.csv\", header=None, names=[\"RandomForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e5acb-ea28-4ce1-aca1-bdce6a82e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual validation set target values\n",
    "y_validation = pd.read_csv(\"y_validation.csv\", header=None, names=[\"Actual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62193377-7fac-4773-95e9-4c1eb69d61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Predictions into a Single DataFrame\n",
    "meta_features = pd.concat([lstm_preds, xgboost_preds, lightgbm_preds, svr_preds, rf_preds], axis=1)\n",
    "meta_target = y_validation[\"Actual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235e0b4-2082-4703-b5c3-1613da082358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Weighted Average of Predictions\n",
    "# Define the weights for each model\n",
    "weights = {\n",
    "    \"LSTM\": 0.2,\n",
    "    \"XGBoost\": 0.2,\n",
    "    \"LightGBM\": 0.2,\n",
    "    \"SVR\": 0.2,\n",
    "    \"RandomForest\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362361ce-fe6b-4812-83f3-90a5644cb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted averaging of predictions\n",
    "weighted_preds = (weights[\"LSTM\"] * lstm_preds[\"LSTM\"] + \n",
    "                  weights[\"XGBoost\"] * xgboost_preds[\"XGBoost\"] + \n",
    "                  weights[\"LightGBM\"] * lightgbm_preds[\"LightGBM\"] + \n",
    "                  weights[\"SVR\"] * svr_preds[\"SVR\"] + \n",
    "                  weights[\"RandomForest\"] * rf_preds[\"RandomForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e0172-8de5-463d-b78a-0e63e714c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Weighted Averaging Ensemble on the Validation Set\n",
    "mae = mean_absolute_error(meta_target, weighted_preds)\n",
    "rmse = np.sqrt(mean_squared_error(meta_target, weighted_preds))\n",
    "\n",
    "print(f\"Weighted Averaging Ensemble MAE: {mae}\")\n",
    "print(f\"Weighted Averaging Ensemble RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326b7f8-470b-4f91-8512-375693eae34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Weighted Averaging Ensemble for Final Predictions (on Test Set)\n",
    "# Load test set predictions from base models\n",
    "lstm_test_preds = pd.read_csv(\"lstm_test_preds.csv\", header=None, names=[\"LSTM\"])\n",
    "xgboost_test_preds = pd.read_csv(\"xgboost_test_preds.csv\", header=None, names=[\"XGBoost\"])\n",
    "lightgbm_test_preds = pd.read_csv(\"lightgbm_test_preds.csv\", header=None, names=[\"LightGBM\"])\n",
    "svr_test_preds = pd.read_csv(\"svr_test_preds.csv\", header=None, names=[\"SVR\"])\n",
    "rf_test_preds = pd.read_csv(\"random_forest_test_preds.csv\", header=None, names=[\"RandomForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f55d3-a7b0-4a83-9d07-ffeb9a8b7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test predictions\n",
    "test_meta_features = pd.concat([lstm_test_preds, xgboost_test_preds, lightgbm_test_preds, svr_test_preds, rf_test_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19007f3a-efe2-4fd5-af24-96328517383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted averaging for test set predictions\n",
    "final_test_preds = (weights[\"LSTM\"] * lstm_test_preds[\"LSTM\"] + \n",
    "                    weights[\"XGBoost\"] * xgboost_test_preds[\"XGBoost\"] + \n",
    "                    weights[\"LightGBM\"] * lightgbm_test_preds[\"LightGBM\"] + \n",
    "                    weights[\"SVR\"] * svr_test_preds[\"SVR\"] + \n",
    "                    weights[\"RandomForest\"] * rf_test_preds[\"RandomForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17e588-8c8c-4763-807f-c16918269c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final predictions\n",
    "pd.DataFrame(final_test_preds, columns=[\"Final_Predictions\"]).to_csv(\"final_weighted_ensemble_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Final weighted ensemble predictions saved as 'final_weighted_ensemble_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Global)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
